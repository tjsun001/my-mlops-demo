name: Deploy Inference Model (EC2)

# Manual deploy only: run via Actions -> Deploy Inference Model (EC2) -> Run workflow

permissions:
  contents: read

on:
  workflow_dispatch:
  schedule:
    - cron: "30 13 * * 0"  # Sundays 8:30am ET (13:30 UTC)

jobs:
  deploy-inference-model:
    runs-on: ubuntu-latest

    steps:
      - name: Restart inference on EC2 and verify /ready + /model/info (Path A)
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ubuntu
          key: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
          script: |
            set -euo pipefail

            APP_DIR="/home/ubuntu/my-mlops-demo"

            echo "[deploy] Restarting inference (Path A: inference pulls model from S3 via production.json)"
            cd "${APP_DIR}"

            echo "[deploy] Pulling latest inference image"
            docker compose pull inference

            echo "[deploy] Restarting inference container"
            docker compose up -d --no-deps --force-recreate inference
            docker compose ps inference

            echo "[deploy] Waiting for inference to become ready..."
            for i in {1..20}; do
              if curl -fsS --max-time 2 "http://127.0.0.1:8000/ready" >/dev/null; then
                echo "[deploy] Inference is ready ✅"
                break
              fi
              echo "[deploy] Not ready yet... ($i/20)"
              sleep 2
            done

            echo "[deploy] /ready:"
            curl -fsS --max-time 5 "http://127.0.0.1:8000/ready" | cat
            echo

            echo "[deploy] /model/info:"
            curl -fsS --max-time 5 "http://127.0.0.1:8000/model/info" | cat
            echo

            echo "[deploy] Done ✅"
